{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def sylco(word) :\n",
    "    word = word.lower()\n",
    "\n",
    "    # exception_add are words that need extra syllables\n",
    "    # exception_del are words that need less syllables\n",
    "\n",
    "    exception_add = ['serious','crucial']\n",
    "    exception_del = ['fortunately','unfortunately']\n",
    "\n",
    "    co_one = ['cool','coach','coat','coal','count','coin','coarse','coup','coif','cook','coign','coiffe','coof','court']\n",
    "    co_two = ['coapt','coed','coinci']\n",
    "\n",
    "    pre_one = ['preach']\n",
    "\n",
    "    syls = 0 #added syllable number\n",
    "    disc = 0 #discarded syllable number\n",
    "\n",
    "    #1) if letters < 3 : return 1\n",
    "    if len(word) <= 3 :\n",
    "        syls = 1\n",
    "        return syls\n",
    "\n",
    "    #2) if doesn't end with \"ted\" or \"tes\" or \"ses\" or \"ied\" or \"ies\", discard \"es\" and \"ed\" at the end.\n",
    "    # if it has only 1 vowel or 1 set of consecutive vowels, discard. (like \"speed\", \"fled\" etc.)\n",
    "\n",
    "    if word[-2:] == \"es\" or word[-2:] == \"ed\" :\n",
    "        doubleAndtripple_1 = len(re.findall(r'[eaoui][eaoui]',word))\n",
    "        if doubleAndtripple_1 > 1 or len(re.findall(r'[eaoui][^eaoui]',word)) > 1 :\n",
    "            if word[-3:] == \"ted\" or word[-3:] == \"tes\" or word[-3:] == \"ses\" or word[-3:] == \"ied\" or word[-3:] == \"ies\" :\n",
    "                pass\n",
    "            else :\n",
    "                disc+=1\n",
    "\n",
    "    #3) discard trailing \"e\", except where ending is \"le\"  \n",
    "\n",
    "    le_except = ['whole','mobile','pole','male','female','hale','pale','tale','sale','aisle','whale','while']\n",
    "\n",
    "    if word[-1:] == \"e\" :\n",
    "        if word[-2:] == \"le\" and word not in le_except :\n",
    "            pass\n",
    "\n",
    "        else :\n",
    "            disc+=1\n",
    "\n",
    "    #4) check if consecutive vowels exists, triplets or pairs, count them as one.\n",
    "\n",
    "    doubleAndtripple = len(re.findall(r'[eaoui][eaoui]',word))\n",
    "    tripple = len(re.findall(r'[eaoui][eaoui][eaoui]',word))\n",
    "    disc+=doubleAndtripple + tripple\n",
    "\n",
    "    #5) count remaining vowels in word.\n",
    "    numVowels = len(re.findall(r'[eaoui]',word))\n",
    "\n",
    "    #6) add one if starts with \"mc\"\n",
    "    if word[:2] == \"mc\" :\n",
    "        syls+=1\n",
    "\n",
    "    #7) add one if ends with \"y\" but is not surrouned by vowel\n",
    "    if word[-1:] == \"y\" and word[-2] not in \"aeoui\" :\n",
    "        syls +=1\n",
    "\n",
    "    #8) add one if \"y\" is surrounded by non-vowels and is not in the last word.\n",
    "\n",
    "    for i,j in enumerate(word) :\n",
    "        if j == \"y\" :\n",
    "            if (i != 0) and (i != len(word)-1) :\n",
    "                if word[i-1] not in \"aeoui\" and word[i+1] not in \"aeoui\" :\n",
    "                    syls+=1\n",
    "\n",
    "    #9) if starts with \"tri-\" or \"bi-\" and is followed by a vowel, add one.\n",
    "\n",
    "    if word[:3] == \"tri\" and word[3] in \"aeoui\" :\n",
    "        syls+=1\n",
    "\n",
    "    if word[:2] == \"bi\" and word[2] in \"aeoui\" :\n",
    "        syls+=1\n",
    "\n",
    "    #10) if ends with \"-ian\", should be counted as two syllables, except for \"-tian\" and \"-cian\"\n",
    "\n",
    "    if word[-3:] == \"ian\" : \n",
    "    #and (word[-4:] != \"cian\" or word[-4:] != \"tian\") :\n",
    "        if word[-4:] == \"cian\" or word[-4:] == \"tian\" :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1\n",
    "\n",
    "    #11) if starts with \"co-\" and is followed by a vowel, check if exists in the double syllable dictionary, if not, check if in single dictionary and act accordingly.\n",
    "\n",
    "    if word[:2] == \"co\" and word[2] in 'eaoui' :\n",
    "\n",
    "        if word[:4] in co_two or word[:5] in co_two or word[:6] in co_two :\n",
    "            syls+=1\n",
    "        elif word[:4] in co_one or word[:5] in co_one or word[:6] in co_one :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1\n",
    "\n",
    "    #12) if starts with \"pre-\" and is followed by a vowel, check if exists in the double syllable dictionary, if not, check if in single dictionary and act accordingly.\n",
    "\n",
    "    if word[:3] == \"pre\" and word[3] in 'eaoui' :\n",
    "        if word[:6] in pre_one :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1\n",
    "\n",
    "    #13) check for \"-n't\" and cross match with dictionary to add syllable.\n",
    "\n",
    "    negative = [\"doesn't\", \"isn't\", \"shouldn't\", \"couldn't\",\"wouldn't\"]\n",
    "\n",
    "    if word[-3:] == \"n't\" :\n",
    "        if word in negative :\n",
    "            syls+=1\n",
    "        else :\n",
    "            pass   \n",
    "\n",
    "    #14) Handling the exceptional words.\n",
    "\n",
    "    if word in exception_del :\n",
    "        disc+=1\n",
    "\n",
    "    if word in exception_add :\n",
    "        syls+=1     \n",
    "\n",
    "    # calculate the output\n",
    "    syll = numVowels - disc + syls\n",
    "\n",
    "    if syll == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return syll\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#new version of sylco\n",
    "\n",
    "def sylco(word):\n",
    "    word = word.lower()\n",
    "\n",
    "    # List of exceptions where words need extra or less syllables\n",
    "    extra_syllables = ['serious', 'crucial']\n",
    "    less_syllables = ['fortunately', 'unfortunately']\n",
    "\n",
    "    # List of prefixes and suffixes that influence syllable count\n",
    "    prefixes_one = ['cool', 'coach', 'coat', 'coal', 'count', 'coin', 'coarse', 'coup', 'coif', 'cook', 'coign', 'coiffe', 'coof', 'court']\n",
    "    prefixes_two = ['coapt', 'coed', 'coinci']\n",
    "    prefixes_pre = ['preach']\n",
    "\n",
    "    # Initialize syllable count and discarded syllable count\n",
    "    syllables = 0\n",
    "    discarded = 0\n",
    "\n",
    "    # If word has 3 or fewer letters, return 1 syllable\n",
    "    if len(word) <= 3:\n",
    "        return 1\n",
    "\n",
    "    # Discard trailing \"e\" except where ending is \"le\"\n",
    "    exceptions_le = ['whole', 'mobile', 'pole', 'male', 'female', 'hale', 'pale', 'tale', 'sale', 'aisle', 'whale', 'while']\n",
    "    if word[-1:] == \"e\":\n",
    "        if word[-2:] == \"le\" and word not in exceptions_le:\n",
    "            pass\n",
    "        else:\n",
    "            discarded += 1\n",
    "\n",
    "    # Count consecutive vowels, triplets, and pairs as one\n",
    "    double_and_triple = len(re.findall(r'[aeiou]{2,3}', word))\n",
    "    discarded += double_and_triple\n",
    "\n",
    "    # Count remaining vowels in word\n",
    "    num_vowels = len(re.findall(r'[aeiou]', word))\n",
    "\n",
    "    # Add one if word starts with \"mc\"\n",
    "    if word[:2] == \"mc\":\n",
    "        syllables += 1\n",
    "\n",
    "    # Add one if ends with \"y\" but is not surrounded by vowel\n",
    "    if word[-1:] == \"y\" and word[-2] not in \"aeoui\":\n",
    "        syllables += 1\n",
    "\n",
    "    # Add one if \"y\" is surrounded by non-vowels and is not in the last word\n",
    "    for i, j in enumerate(word):\n",
    "        if j == \"y\":\n",
    "            if (i != 0) and (i != len(word) - 1):\n",
    "                if word[i - 1] not in \"aeoui\" and word[i + 1] not in \"aeoui\":\n",
    "                    syllables += 1\n",
    "\n",
    "    # Add one if starts with \"tri-\" or \"bi-\" and is followed by a vowel\n",
    "    if word[:3] == \"tri\" and word[3] in \"aeoui\":\n",
    "        syllables += 1\n",
    "\n",
    "    if word[:2] == \"bi\" and word[2] in \"aeoui\":\n",
    "        syllables += 1\n",
    "\n",
    "    # Add one if ends with \"-ian\" and is not \"-tian\" or \"-cian\"\n",
    "    if word[-3:] == \"ian\":\n",
    "        if word[-4:] != \"cian\" or word[-4:] != \"tian\":\n",
    "            syllables += 1\n",
    "\n",
    "    # Add one if starts with \"co-\" and is followed by a vowel\n",
    "    if word[:2] == \"co\" and word[2] in 'aeoui':\n",
    "        if word[:4] in prefixes_two or word[:5] in prefixes_two or word[:6] in prefixes_two:\n",
    "            syllables += 1\n",
    "        elif word[:4] in prefixes_one or word[:5] in prefixes_one or word[:6] in prefixes_one:\n",
    "            pass\n",
    "        else:\n",
    "            syllables += 1\n",
    "\n",
    "    # Add one if starts with \"pre-\" and is followed by a vowel\n",
    "    if word[:3] == \"pre\" and word[3] in 'aeoui':\n",
    "        if word[:6] in prefixes_pre:\n",
    "            pass\n",
    "        else:\n",
    "            syllables += 1\n",
    "\n",
    "    # Check for \"-n't\" and cross-match with dictionary to add syllable\n",
    "    negatives = [\"doesn't\", \"isn't\", \"shouldn't\", \"couldn't\", \"wouldn't\"]\n",
    "    if word[-3:] == \"n't\":\n",
    "        if word in negatives:\n",
    "            syllables += 1\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # Handling exceptional words\n",
    "    if word in less_syllables:\n",
    "        discarded += 1\n",
    "\n",
    "    if word in extra_syllables:\n",
    "        syllables += 1\n",
    "\n",
    "    # Calculate the output\n",
    "    total_syllables = num_vowels - discarded + syllables\n",
    "\n",
    "    # Adjust if total syllables is 0\n",
    "    if total_syllables == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return total_syllables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words are:\n",
      "473\n",
      "Total correct are:\n",
      "417\n",
      "\n",
      "Precision: 88.16%\n",
      "\n",
      "Contingency table:\n",
      "Syllables\tCorrect\tIncorrect\tTotal\n",
      "1\t\t89\t0\t\t89\n",
      "2\t\t82\t2\t\t84\n",
      "3\t\t78\t11\t\t89\n",
      "4\t\t76\t14\t\t90\n",
      "5\t\t41\t17\t\t58\n",
      "6\t\t35\t10\t\t45\n",
      "7\t\t16\t2\t\t18\n"
     ]
    }
   ],
   "source": [
    "one_syllable_words = [\n",
    "    \"Strong\", \"Big\", \"Soft\", \"Smart\", \"Best\", \"Thin\", \"Clear\", \"Sweet\", \"Wild\", \"Plain\",\n",
    "    \"Lean\", \"Love\", \"Fish\", \"Duck\", \"Dream\", \"Care\", \"Work\", \"Ask\", \"Point\", \"Bow\",\n",
    "    \"Ship\", \"Pen\", \"Key\", \"Faith\", \"Breath\", \"Peace\", \"Cake\", \"Bed\", \"Rock\", \"Home\",\n",
    "    \"Hate\", \"Zone\", \"Moon\", \"Cord\", \"Beep\", \"Corn\", \"Sword\", \"Cheeks\", \"Tongue\", \"Kids\",\n",
    "    \"Ice\", \"Board\", \"Life\", \"One\", \"Day\", \"Tip\", \"Heart\", \"Ate\", \"Month\", \"Death\", \"Tea\",\n",
    "    \"Out\", \"Three\", \"Two\", \"Soul\", \"Age\", \"Mouth\", \"Dog\", \"Cat\", \"Net\", \"Earth\", \"Near\",\n",
    "    \"Ace\", \"Ring\", \"Man\", \"Go\", \"Tree\", \"End\", \"Time\", \"Sing\", \"Song\", \"Foot\", \"Hand\",\n",
    "    \"Feet\", \"Toe\", \"North\", \"Live\", \"Lamb\", \"Green\", \"Old\", \"Hard\", \"High\", \"Down\", \"Bad\",\n",
    "    \"Sick\", \"Far\", \"Full\", \"Dry\", \"Odd\"\n",
    "]\n",
    "\n",
    "two_syllables_words = [\n",
    "    \"Happy\", \"Perfect\", \"Joyful\", \"Thirsty\", \"Awkward\", \"Tender\", \"Heavy\", \"Standard\",\n",
    "    \"Thankful\", \"Common\", \"Donate\", \"Picture\", \"Bottle\", \"Wonder\", \"Forward\", \"Distance\",\n",
    "    \"Mirror\", \"Party\", \"Journey\", \"Market\", \"Fashion\", \"Champion\", \"Water\", \"Future\",\n",
    "    \"Basket\", \"Picnic\", \"Sugar\", \"Office\", \"Challenge\", \"River\", \"Circus\", \"Apple\",\n",
    "    \"Auto\", \"Lizard\", \"Baseball\", \"Helmet\", \"Decode\", \"April\", \"Feather\", \"Cookies\",\n",
    "    \"Classroom\", \"Father\", \"Yellow\", \"Power\", \"Hero\", \"Pirate\", \"Ally\", \"Nothing\",\n",
    "    \"Forty\", \"Open\", \"Monkey\", \"System\", \"Secret\", \"Mountain\", \"Lemon\", \"Morning\",\n",
    "    \"Anime\", \"Baby\", \"Story\", \"Blanket\", \"Wonder\", \"Number\", \"Service\", \"Allow\",\n",
    "    \"Cricket\", \"Poison\", \"Caution\", \"Rocket\", \"Habit\", \"Total\", \"Battle\", \"Weekend\",\n",
    "    \"Ticket\", \"Struggle\", \"Fancy\", \"Figure\", \"Chamber\", \"Jingle\", \"Solve\", \"Sorrow\",\n",
    "    \"Motion\", \"Believe\", \"Solar\", \"Polar\"\n",
    "]\n",
    "\n",
    "three_syllables_words = [\n",
    "    \"Careful\", \"Adopted\", \"Bottomless\", \"Limited\", \"Elastic\", \"Insecure\", \"Athletic\", \"Circular\",\n",
    "    \"Potential\", \"Complete\", \"Permanent\", \"Impressive\", \"Celebrate\", \"Revenge\", \"Remember\", \"Discipline\",\n",
    "    \"Separate\", \"Consummate\", \"Emanate\", \"Encounter\", \"Surrender\", \"Duplicate\", \"Audition\", \"Family\",\n",
    "    \"Happiness\", \"Piano\", \"Animal\", \"Energy\", \"Syllable\", \"Pollution\", \"Basketball\", \"Calendar\",\n",
    "    \"Mystery\", \"Perfection\", \"Buffalo\", \"Dinosaur\", \"Octopus\", \"Crocodile\", \"Tomato\", \"Elephant\",\n",
    "    \"Banana\", \"Envelope\", \"Chimpanzee\", \"Celery\", \"Vitamin\", \"Tomorrow\", \"Diamond\", \"Memory\",\n",
    "    \"Musical\", \"Melody\", \"Mercury\", \"Volcano\", \"Copyright\", \"Medical\", \"Difficult\", \"Feminine\",\n",
    "    \"Masculine\", \"Dangerous\", \"Healthy\", \"Internal\", \"Radio\", \"Uniform\", \"Electric\", \"Tropical\",\n",
    "    \"United\", \"Opposite\", \"Chemical\", \"Accurate\", \"Serious\", \"Curious\", \"Difficult\", \"Radical\",\n",
    "    \"Biblical\", \"Abdicate\", \"Companion\", \"Character\", \"Uniform\", \"Abolish\", \"Article\", \"Graduate\",\n",
    "    \"Average\", \"Discover\", \"Exercise\", \"Ornament\", \"Resolve\", \"Ambition\", \"History\", \"Camera\", \"Holiday\"\n",
    "]\n",
    "\n",
    "four_syllables_words = [\n",
    "    \"Ordinary\", \"Intelligent\", \"Responsible\", \"Disposable\", \"Ambitious\", \"Infectious\", \"Approachable\", \"Accessible\",\n",
    "    \"Unbreakable\", \"Dependable\", \"Predictable\", \"Organized\", \"Pessimistic\", \"Experience\", \"Literature\", \"Community\",\n",
    "    \"Television\", \"Constellation\", \"Revolution\", \"Insulation\", \"Territory\", \"Calamity\", \"Mechanism\", \"Admiration\",\n",
    "    \"Audacity\", \"Procrastinate\", \"Collaborate\", \"Abbreviate\", \"Exfoliate\", \"Accommodate\", \"Eliminate\", \"Evacuate\",\n",
    "    \"Contaminate\", \"Accompany\", \"Accelerate\", \"Insinuate\", \"Caterpillar\", \"Relaxation\", \"Psychology\", \"Degenerate\",\n",
    "    \"Incubator\", \"Kindergarten\", \"Tribalism\", \"Complexity\", \"Matrimony\", \"Anatomy\", \"Presidential\", \"Helicopter\",\n",
    "    \"Perimeter\", \"Architecture\", \"Ecosystem\", \"Transportation\", \"Generator\", \"Equality\", \"Organism\", \"Celebrity\",\n",
    "    \"Automatic\", \"Anaconda\", \"Dismantle\", \"Activities\", \"Compatible\", \"Intervene\", \"Encapsulate\", \"Predominate\",\n",
    "    \"Legitimate\", \"Enumerate\", \"Dissociate\", \"Incorporate\", \"Overpower\", \"Rationalize\", \"Internalize\", \"Stereotype\",\n",
    "    \"Elaborate\", \"Emasculate\", \"Maleficent\", \"Professional\", \"Independent\", \"Infinitive\", \"Appetizing\", \"Material\",\n",
    "    \"Alcoholic\", \"Educated\", \"Emotional\", \"Illegible\", \"Desirable\", \"Conservative\", \"Familiar\", \"Believable\",\n",
    "    \"Unfortunate\", \"Sanitary\"\n",
    "]\n",
    "\n",
    "five_syllables_words = [\n",
    "    \"Conversational\", \"Inexcusable\", \"Impressionable\", \"Intolerable\", \"Simultaneous\", \"Irreplaceable\", \"Unacceptable\", \"Supernatural\",\n",
    "    \"Insignificant\", \"Accommodating\", \"Administrative\", \"Apologetic\", \"Deteriorate\", \"Decontaminate\", \"Deactivated\", \"Incapacitate\",\n",
    "    \"Underestimate\", \"Overcompensate\", \"Familiarize\", \"Overestimate\", \"Conceptualize\", \"Abomination\", \"Capitalism\", \"Communication\",\n",
    "    \"Organization\", \"Administration\", \"Commemoration\", \"Manipulator\", \"Characteristic\", \"Accumulation\", \"Choreography\", \"Durability\",\n",
    "    \"Capability\", \"Materialize\", \"Inconvenience\", \"Disorientate\", \"Intermediate\", \"Underestimate\", \"Misappropriate\", \"Discrimination\",\n",
    "    \"Electricity\", \"Curiosity\", \"Civilization\", \"Generosity\", \"Interpretation\", \"Anticipation\", \"Vocabulary\", \"International\",\n",
    "    \"Opportunity\", \"Intellectual\", \"Humiliation\", \"Annihilation\", \"Equilibrium\", \"Invigorating\", \"Insignificant\", \"Undeniable\",\n",
    "    \"Unconditional\", \"Intellectual\"\n",
    "]\n",
    "\n",
    "six_syllables_words = [\n",
    "    \"Categorizable\", \"Hallucinogenic\", \"Differentiated\", \"Identifiable\", \"Ecclesiastical\", \"Capitalization\", \"Categorization\", \"Divisibility\",\n",
    "    \"Disassociation\", \"Familiarization\", \"Humidification\", \"Hospitalization\", \"Reconsideration\", \"Idealization\", \"Nationalization\", \"Legitimization\",\n",
    "    \"Excommunication\", \"Illegitimacy\", \"Saponification\", \"Biodiversity\", \"Responsibility\", \"Personification\", \"Voluminosity\", \"Desertification\",\n",
    "    \"Extraterrestrial\", \"Accountability\", \"Encyclopedia\", \"Identification\", \"Revolutionary\", \"Characterization\", \"Generalization\", \"Beneficiary\",\n",
    "    \"Biotechnology\", \"Humanitarian\", \"Autobiography\", \"Rationalization\", \"Initialization\", \"Adaptability\", \"Bioluminescence\", \"Electromagnetic\",\n",
    "    \"Interrogatory\", \"Intercommunicate\", \"Editorialize\", \"Overgeneralize\", \"Telecommunicate\"\n",
    "]\n",
    "\n",
    "seven_syllables_words = [\n",
    "    \"Unconventionality\", \"Sentimentalization\", \"Immeasurability\", \"Irreversibility\", \"Maneuverability\", \"Editorialization\", \"Oversimplification\",\n",
    "    \"Inaccessibility\", \"Incompatibility\", \"Decriminalization\", \"Inaccessibility\", \"Impermeability\", \"Compartmentalization\", \"Indispensability\",\n",
    "    \"Microbiological\", \"Parasitological\", \"Inadmissibility\", \"Neuropsychological\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Calculate syllables and compare with actual syllable count\n",
    "words_lists = [one_syllable_words, two_syllables_words, three_syllables_words, \n",
    "               four_syllables_words, five_syllables_words, six_syllables_words, seven_syllables_words]\n",
    "\n",
    "\n",
    "total_correct = 0\n",
    "total_count = 0\n",
    "table = []\n",
    "\n",
    "for i, words in enumerate(words_lists):\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    count = 0\n",
    "    incorrect_words = []\n",
    "    for word in words:\n",
    "        syllables = sylco(word)\n",
    "        actual_syllables = i + 1\n",
    "        if syllables == actual_syllables:\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "            incorrect_words.append((word, syllables))\n",
    "        count += 1\n",
    "    total_correct += correct\n",
    "    total_count += count\n",
    "    table.append((correct, incorrect, count))\n",
    "    \n",
    "    # Print incorrect words\n",
    "    # if incorrect_words:\n",
    "    # print(\"\\nWords in {}-syllables list identified erroneously:\".format(i + 1))\n",
    "    # for word, syllables in incorrect_words:\n",
    "    # print(\"Word: {}, Identified Syllables: {}\".format(word, syllables))\n",
    "\n",
    "# Calculate precision\n",
    "precision = total_correct / total_count * 100\n",
    "print(\"Total words are:\")\n",
    "print(total_count)\n",
    "\n",
    "print(\"Total correct are:\")\n",
    "print(total_correct)\n",
    "\n",
    "# Print precision\n",
    "print(\"\\nPrecision: {:.2f}%\".format(precision))\n",
    "\n",
    "# Print contingency table\n",
    "print(\"\\nContingency table:\")\n",
    "print(\"Syllables\\tCorrect\\tIncorrect\\tTotal\")\n",
    "for i, (correct, incorrect, total) in enumerate(table, start=1):\n",
    "    print(\"{}\\t\\t{}\\t{}\\t\\t{}\".format(i, correct, incorrect, total))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
